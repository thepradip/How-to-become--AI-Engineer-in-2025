
<img src="GenAI2025.png" alt="Generative AI" width="800">



## Free Generative AI Platform/App:
Discover a free generative AI platform where you can ask questions, summarize texts, generate stunning images, and create content like code, stories, and video scripts all without any installations. 
Dive in and play to understand how AI works, master the art of prompt writing, and build your innovative applications seamlessly. platform like chatgpt, XAI(twitter), Gemini from google, groq.


- **[ChatGPT](https://chat.openai.com/)**: Developed by OpenAI, ChatGPT is a conversational AI model capable of understanding and generating human-like text, assisting with a variety of tasks.

- **[DeepSeek](https://www.deepseek.com/)**: DeepSeek offers advanced AI models, including DeepSeek-V3, known for its rapid inference and high performance in various benchmarks.

- **[XAI](https://x.ai/api)**: XAI provides the Grok API, granting developers access to cutting-edge language models with features like function calling and extended context length.

- **[Groq](https://console.groq.com/keys)**: GroqCloud delivers high-performance computing solutions, enabling users to manage API keys and access powerful processing capabilities.

- **[Gemini](https://gemini.google.com/app)**: Developed by Google, Gemini is a generative AI chatbot designed to assist users across various tasks with advanced conversational abilities.

- **[Bing](https://www.bing.com/)**: Microsoft's search engine, Bing, offers web search capabilities along with integrated AI features to enhance the user experience.

- **[YOU](https://you.com)**: You.com is an AI-driven search platform focusing on workplace productivity, providing personalized search results and tools.

- **[Poe](https://poe.com/)**: Poe allows users to interact with various AI models, including ChatGPT and Claude, facilitating diverse conversational experiences.

- **[Perplexity](https://www.perplexity.ai/)**: Perplexity AI is a conversational search engine that provides direct answers to user queries by leveraging large language models.


  
# GenerativeAI Foundation
A solid foundation in mathematics—covering probability, algebra, and calculus—and proficiency in programming languages like Python or JavaScript are essential for generative AI. While no-code platforms offer accessible solutions, mastering these fundamentals enables you to implement customizations more efficiently.


## Programming



- **[AI Python for Beginners](https://learn.deeplearning.ai/courses/ai-python-for-beginners/lesson/1/introduction)**: An introductory course by DeepLearning.AI that teaches Python programming with AI assistance, covering basics like variables, functions, and data handling.

- **[Crash Course on Python](https://www.coursera.org/learn/python-crash-course)**: Offered by Google on Coursera, this course provides foundational knowledge to write simple Python programs using common structures.

- **[Generative AI with JavaScript](https://www.youtube.com/playlist?list=PLlrxD0HtieHi5ZpsHULPLxm839IrhmeDk)**: A YouTube playlist guiding learners on integrating generative AI into JavaScript projects, covering key concepts and practical implementations.

- **[JavaScript Basics](https://www.coursera.org/learn/javascript-basics?specialization=javascript-beginner)**: A beginner-level course by the University of California, Davis, introducing the fundamentals of JavaScript, including variables, arrays, and core programming structures.

- **[JavaScript Mastery](https://www.youtube.com/@javascriptmastery/videos)**: A YouTube channel offering a collection of advanced JavaScript projects and tutorials to enhance coding skills.

- **[LeetCode Explore](https://leetcode.com/explore/)**: A platform providing coding challenges and problems to practice and improve programming skills across various topics.

- **[10 Minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)**: A quick guide to the pandas library, introducing data structures and essential functionalities for data analysis in Python.

- **[Python Beginner Series - IPL](https://github.com/thepradip/Python-Beginner-Series-IPL)**: A GitHub repository offering a series of beginner-friendly Python tutorials, using IPL data for practical learning.

- **[Chainlit Documentation](https://docs.chainlit.io/get-started/overview)**: Official documentation for Chainlit, an open-source Python package to build production-ready conversational AI applications.

- **[Streamlit Documentation](https://docs.streamlit.io/)**: Comprehensive guides and references for Streamlit, an open-source Python framework for creating dynamic data applications.

- **[DataCamp: Python and Plotting](https://www.youtube.com/playlist?list=PLjgj6kdf_snaw8QnlhK5f3DzFDFKDU5f4)**: A YouTube playlist by DataCamp covering Python programming and data visualization techniques.



## Math [12th basic math requirements]
12th basic math requirements. probability, Linear Algebra, Stats, etc

### Probability and Statistics:
- **[Probability and Statistics in Data Science using Python](https://www.edx.org/course/probability-and-statistics-in-data-science-using-python-2)**: Offered by UCSanDiegoX on edX, this course teaches statistical and probabilistic approaches to understand and gain insights from data using Python. 

- **[Khan Academy: Probability](https://www.youtube.com/playlist?list=PLC58778F28211FA19)**: A comprehensive YouTube playlist by Khan Academy covering fundamental concepts in probability.

- **[Khan Academy: Statistics](https://www.youtube.com/playlist?list=PL1328115D3D8A2566)**: A YouTube playlist by Khan Academy that provides an in-depth understanding of basic statistics.

- **[Basic Statistics](https://www.coursera.org/learn/basic-statistics)**: This Coursera course from the University of Amsterdam introduces foundational statistical concepts, including descriptive statistics, probability distributions, and inferential statistics. 

### Algebra:
- **[Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)**: A YouTube series by 3Blue1Brown that visually explores the fundamental concepts of linear algebra. 
These resources provide a solid foundation in probability, statistics, and algebra, essential for data science and related fields. 


# GenAI 
## Beginner:
 Understand key concepts such as transformers encoder, decoder, and essential AI terminology to grasp how these models work. Gradually learn to use APIs from platforms like OpenAI, Huggingface, and  Claude to build and customize your AI-powered products. This structured approach enables you to implement customizations efficiently in generative AI.


- **[Transformers](https://huggingface.co/learn/nlp-course/chapter1/1)**: A comprehensive course by Hugging Face that teaches natural language processing (NLP) using their libraries, including Transformers, Datasets, Tokenizers, and Accelerate. ([huggingface.co](https://huggingface.co/learn/nlp-course/en/chapter1/1?utm_source=chatgpt.com))

- **[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)**: A visual and intuitive guide by Jay Alammar explaining the Transformer model architecture and its application in machine translation tasks. ([jalammar.github.io](https://jalammar.github.io/illustrated-transformer/?utm_source=chatgpt.com))

- **[Generative AI for Everyone](https://www.coursera.org/learn/generative-ai-for-everyone)**: An introductory course by DeepLearning.AI, led by Andrew Ng, that explores the fundamentals of generative AI, its applications, and implications across various industries. 

- **[Introduction to Generative AI Learning Path](https://www.cloudskillsboost.google/paths/118)**: A learning path by Google Cloud that provides an overview of generative AI concepts, including large language models and responsible AI principles. 

- **[Generative AI for Beginners](https://learn.microsoft.com/en-gb/shows/generative-ai-for-beginners/)**: A comprehensive 18-lesson course by Microsoft Cloud Advocates covering the fundamentals of building generative AI applications. 

- **[How Diffusion Models Work](https://learn.deeplearning.ai/courses/diffusion-models/lesson/1/introduction)**: A short course by DeepLearning.AI that delves into the mechanics of diffusion models, explaining how algorithms like Midjourney and Stable Diffusion generate images from prompts. 


## Prompt: Language to communicate to LLM
Prompt engineering is designing and crafting effective prompts to optimize the performance of large language models (LLMs). 
These courses, such as “Prompt Engineering for Everyone” and OpenAI’s and Anthropic’s collections, guide learners in understanding how to structure prompts, leverage model capabilities, and create customized queries for specific tasks. 
They provide practical techniques, examples, and strategies for improving interaction with LLMs across diverse applications.


- **[ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)**: A short course by DeepLearning.AI and OpenAI that teaches best practices for prompt engineering to build powerful applications using large language models. 

- **[Prompt Engineering for Everyone](https://www.coursera.org/learn/generative-ai-prompt-engineering-for-everyone)**: An introductory course by IBM on Coursera that covers the fundamentals of prompt engineering in generative AI. ([coursera.org](https://www.coursera.org/learn/prompt-engineering?utm_source=chatgpt.com))

- **[Prompt Engineering Guide](https://www.promptingguide.ai/)**: A comprehensive guide that offers best practices, techniques, and examples for crafting effective prompts in AI models. ([promptingguide.ai](https://www.promptingguide.ai/?utm_source=chatgpt.com))

- **[Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)**: A curated list of ChatGPT prompts to inspire and enhance AI interactions. 

- **[OpenAI Prompt Examples](https://platform.openai.com/docs/examples)**: Official OpenAI examples demonstrating effective prompt usage across various scenarios. 
- **[Anthropic Prompt Library](https://docs.anthropic.com/en/prompt-library/library)**: A library of prompt examples and guidelines provided by Anthropic to assist in AI model interactions. 

  

## GenAI Level 2 and Agent Courses
These advanced courses offer a practical deep dive into generative AI frameworks like LangChain, LlamaIndex, and Autogen, emphasizing hands-on projects to build real-world applications. With a focus on agentic systems and retrieval-augmented generation, learners can enhance their expertise and confidently navigate cutting-edge AI technologies. Completing these courses ensures proficiency in key tools and frameworks, setting the stage for impactful development work.


- **[Kaggle | 5-Day Generative AI](https://www.kaggle.com/learn-guide/5-day-genai)**: A structured program offering a hands-on introduction to generative AI concepts and techniques over five days.

- **[Generative AI with LLMs](https://www.coursera.org/learn/generative-ai-with-llms)**: A Coursera course exploring constructing and fine-tuning large language models for AI applications.

- **[LangChain & Vector Databases in Production | Activeloop](https://learn.activeloop.ai/courses/langchain)**: Learn to integrate LangChain with vector databases for advanced AI applications.

- **[Building AI Applications with Haystack](https://www.deeplearning.ai/short-courses/building-ai-applications-with-haystack/)**: A DeepLearning.AI short course focusing on using Haystack for AI-powered search and retrieval systems.

- **[Building Agentic RAG with LlamaIndex](https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/)**: Learn to build Retrieval-Augmented Generation (RAG) systems using LlamaIndex for enhanced AI-driven responses.

- **[Functions, Tools, and Agents in LangChain](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)**: A practical guide to utilizing LangChain’s agentic capabilities for AI applications.

- **[AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)**: Explore agent-based architectures using LangGraph in this DeepLearning.AI course.

- **[AI Agentic Design Patterns with Autogen](https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/)**: Implement agentic AI design patterns with Autogen in real-world applications.

- **[Multi-AI Agent Systems with CrewAI](https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/)**: A hands-on course on building multi-agent AI systems using CrewAI.

- **[Practical Multi-AI Agents and Advanced Use Cases with CrewAI](https://learn.deeplearning.ai/courses/practical-multi-ai-agents-and-advanced-use-cases-with-crewai/lesson/1/introduction)**: A deeper dive into advanced use cases for CrewAI-based multi-agent systems.

- **[Introducing Multimodal Llama 3.2](https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/)**: An introduction to the multimodal capabilities of Meta’s Llama 3.2.

- **[Building Systems with ChatGPT](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)**: A practical course on integrating ChatGPT into AI-driven applications.

- **[HuggingFace NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1)**: A structured NLP course from Hugging Face covering key concepts and model fine-tuning.

- **[SmolAgents Documentation](https://huggingface.co/docs/smolagents/en/index)**: A guide for SmolAgents, a lightweight agent-based framework.

- **[Evaluating and Debugging Generative AI Models Using Weights and Biases](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai/)**: Learn to assess, optimize, and debug generative AI applications.

- **[LangChain for LLM Application Development](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)**: Leverage LangChain for developing production-grade AI solutions.

- **[Building and Evaluating Advanced RAG Applications](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-16+V1)**: A practical guide to implementing Retrieval-Augmented Generation (RAG) using NVIDIA’s AI tools.

- **[Kaggle Learn](https://www.kaggle.com/learn)**: A free, hands-on learning platform for machine learning, data science, and AI topics.

- **[LangChain: Chat with Your Data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)**: Build AI-powered chatbots that interact with custom datasets.

- **[Building RAG Agents with LLMs | NVIDIA](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-15+V1)**: An advanced course on constructing RAG-based AI agents.

- **[OpenAI | Build Hours](https://github.com/openai/build-hours)**: A GitHub repository by OpenAI containing resources and build sessions for developers using AI models.

This collection of resources covers foundational and advanced topics in generative AI, retrieval-augmented generation, AI agents, and model evaluation. 



## AI Observability | Monitoring: If you can't measure, you can't understand it

These courses focus on AI observability and operational excellence, offering tools and frameworks like Arize, LangSmith, MLflow, and ZenML for monitoring, testing, and managing large language models (LLMs). Learners gain practical insights into LLMOps, quality assurance, and automated testing, ensuring safety and performance in AI applications. With hands-on content and cutting-edge platforms, these courses empower participants to build reliable, scalable, and well-monitored AI systems.


- **[Arize | LLM Observability](https://arize.com/blog-course/large-language-model-monitoring-observability/)**: A comprehensive guide on monitoring and observability techniques for large language models, provided by Arize.

- **[LangSmith](https://docs.smith.langchain.com/)**: Documentation for LangSmith, a tool designed to enhance the development and deployment of language models.

- **[LangSmith | Course](https://academy.langchain.com/enrollments)**: An educational course offering in-depth knowledge and practical skills for utilizing LangSmith in language model projects.

- **[MLflow](https://mlflow.org/)**: An open-source platform for managing the end-to-end machine learning lifecycle, including experimentation, reproducibility, and deployment.

- **[MLOps with MLflow | Hugging Face & Duke | Course](https://www.coursera.org/learn/mlops-mlflow-huggingface-duke/)**: A Coursera course in collaboration with Hugging Face and Duke University, focusing on MLOps practices using MLflow.

- **[LLM Operations | GCP, Azure, AWS](https://www.coursera.org/specializations/large-language-model-operations)**: A specialization on Coursera covering operations and management of large language models across major cloud platforms.

- **[LLMOps | Google](https://learn.deeplearning.ai/courses/llmops/lesson/1/introduction)**: A course by DeepLearning.AI introducing best practices for managing and deploying large language models in production.

- **[Automated Testing in LLMOps](https://learn.deeplearning.ai/courses/automated-testing-llmops/lesson/1/introduction)**: A DeepLearning.AI course focusing on automated testing methodologies within the context of LLM operations.

- **[Quality and Safety in LLM Applications](https://learn.deeplearning.ai/courses/quality-safety-llm-applications/lesson/1/introduction)**: A course addressing the quality assurance and safety considerations essential for deploying large language model applications.

- **[AgentOps](https://github.com/AgentOps-AI/AgentStack)**: An open-source framework for managing and deploying AI agents, facilitating streamlined operations in AI projects.

- **[Comet | LLMOps](https://www.comet.com/site/llm-course/)**: A course by Comet focusing on operations and management practices for large language models.

- **[Deepchecks](https://www.deepchecks.com/llm-evaluation/)**: An end-to-end evaluation and observability solution for large language model applications, offering automated scoring, version comparison, and monitoring features. 

- **[Evidently AI](https://www.evidentlyai.com/)**: An AI observability platform providing tools for evaluating, testing, and monitoring AI-powered products, including LLMs and traditional ML models. 

- **[Metaflow](https://github.com/Netflix/metaflow)**: An open-source platform developed by Netflix to simplify the building and management of real-life data science projects, enhancing productivity for data scientists. 

- **[BentoML](https://www.bentoml.com/)**: A unified inference platform that enables scalable deployment of AI models, offering flexibility and performance optimization for various AI applications. 

- **[ZenML](https://www.zenml.io/)**: An open-source MLOps framework that integrates with existing infrastructure and tools, facilitating seamless ML and LLM operations. 

This collection of resources provides comprehensive insights into the observability, management, and operationalization of large language models and machine learning workflows. 



    

## Image and Video Generation:
These courses and platforms explore Multimodal image and video generation using cutting-edge tools like diffusion models, DALL-E, and Runway Gen-2. Learners can master techniques for crafting prompts and experimenting with tools like MidJourney, Sora, and Leonardo.ai to create stunning visual content. With practical experiments and creative freedom, these resources empower users to harness generative AI for artistic and professional projects.


- **[How Diffusion Models Work](https://learn.deeplearning.ai/courses/diffusion-models/lesson/1/introduction)**: A short course by DeepLearning.AI that provides a concrete implementation of image generation using diffusion models, guiding learners through the technical details of these algorithms. 

- **[Hugging Face Diffusion Models Course](https://huggingface.co/learn/diffusion-course/en/unit0/1)**: A free course that covers the theory behind diffusion models, teaching how to generate images and audio with the Diffusers library, train models from scratch, and fine-tune existing models. 

- **[50+ Best DALL·E Prompts Examples](https://mockey.ai/blog/dall-e-prompts/)**: A guide showcasing over 50 DALL·E prompt examples, providing insights into crafting effective prompts for generating diverse and creative images. 

- **[Midjourney Community Showcase](https://www.midjourney.com/explore?tab=top)**: A platform where users can explore top creations made with Midjourney, offering inspiration and examples of AI-generated art. 

- **[Sora Featured Explorations](https://sora.com/explore/featured)**: A collection of featured explorations on Sora, highlighting innovative projects and creative works. 

- **[Runway Research | Gen-2](https://runwayml.com/research/gen-2)**: An overview of Runway's Gen-2, a multimodal AI system capable of generating novel videos using text, images, or video clips, pushing the boundaries of AI-driven content creation. 

This collection of resources offers a comprehensive overview of diffusion models, prompt engineering, and cutting-edge AI tools for creative applications. 
Exploring AI-driven image generation tools like DALL·E, Midjourney, Leonardo.ai, Kling, and Sora can offer diverse creative possibilities

## Best Free AI Conferences:
Exploring AI conferences that are both impactful and free can provide valuable insights without financial constraints.
- **[AI Summit 2025|AI Leadership](https://www.youtube.com/watch?v=L89GzWEILkM&ab_channel=AIEngineer)**: This is the AI Summit 2025 part 1 Leadership YouTube playlist, which offers insights into AI Agents and deploying large language models (LLMs) in production environments. It covers best practices and real-world applications.
- - **[AI Summit 2025|AI Leadership](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=39s&ab_channel=AIEngineer))**: AI Summit 2025 part 2 AI Agent YouTube playlist offering insights into AI Agent, deploying Large Language Models (LLMs) in production environments, covering best practices and real-world applications.

- **[LLM in Production](https://www.youtube.com/playlist?list=PL3vkEKxWd-us5YvvuvYkjP_QGlgUq3tpA)**: A YouTube playlist offering insights into deploying Large Language Models (LLMs) in production environments, covering best practices and real-world applications.

- **[LLM in Production - Part II](https://www.youtube.com/playlist?list=PL3vkEKxWd-uupBSWL-DbVJuCMqXO9Z3Z4)**: The second installment of the series, delving deeper into advanced topics related to LLM deployment and maintenance in production settings.

- **[LLM in Production - Part III](https://www.youtube.com/playlist?list=PL3vkEKxWd-usFkc3977ZeexYXS3GgDVSO)**: The third part of the series, focusing on the latest developments and case studies in implementing LLMs in production.

- **[MLOps Community](https://mlops.community/)**: A collaborative platform dedicated to sharing real-world best practices in Machine Learning Operations (MLOps), featuring events, discussions, and resources from industry professionals.

These resources provide comprehensive guidance on deploying and managing Large Language Models in production environments, 
as well as insights into effective MLOps practices. 


## GenAI Framework, Library, and Tools:
Unlock the full potential of Generative AI with powerful frameworks like **LangChain** and **LlamaIndex**, perfect for seamless integration and advanced functionality. Harness the capabilities of agentic frameworks such as **Langgraph**, **CrewAI**, **Autogen**, and **Phidata** to create autonomous AI systems that handle complex tasks effortlessly. For those who prefer a no-code approach, platforms like **Flowise** and **Langflow** make designing and deploying sophisticated AI applications simple and accessible. Empower your AI journey with these versatile tools and bring your innovative ideas to life with ease.


- **[OpenAI Cookbook](https://cookbook.openai.com/)**: A comprehensive guide by OpenAI offering practical examples and best practices for using their API, aiding developers in effectively integrating AI functionalities into applications.

- **[Gemini Cookbook](https://ai.google.dev/gemini-api/cookbook)**: Google's resource providing detailed instructions and examples for utilizing the Gemini API, assisting developers in building and optimizing AI-driven applications.

- **[Langchain](https://python.langchain.com/docs/introduction/)**: A framework designed to simplify the development of applications using large language models, offering modular components and extensive documentation for streamlined integration.

- **[LLamaindex](https://docs.llamaindex.ai/en/stable/#introduction)**: A tool that facilitates the indexing and querying of large-scale language models, enabling efficient retrieval and interaction with vast datasets.

- **[Haystack](https://haystack.deepset.ai/)**: An open-source framework for building search systems, question-answering pipelines, and conversational AI applications, supporting developers in creating robust NLP solutions.

- **[Phidata](https://www.phidata.com/)**: A platform offering tools and services for data engineering and analytics, assisting teams in managing data workflows and building scalable data solutions.

- **[Lang Graph](https://www.langchain.com/langgraph)**: A visual tool that aids in understanding and designing language model workflows, providing insights into the structure and flow of language processing tasks.

- **[Workflow](https://docs.llamaindex.ai/en/stable/module_guides/workflow/)**: Documentation detailing the workflow modules of LLamaindex, guiding users through the process of setting up and managing language model operations.

- **[OpenAI Swarm](https://github.com/openai/swarm)**: An open-source project by OpenAI focusing on collaborative AI systems, providing resources and code for developing multi-agent AI applications.

- **[Crew AI](https://www.crewai.com/)**: A platform that enables the creation and management of AI agents, facilitating the development of collaborative and autonomous AI systems.

- **[Autogen](https://microsoft.github.io/autogen/0.2/)**: Microsoft's toolkit for automated code generation, assisting developers in leveraging AI to write code snippets and accelerate development processes.

- **[Pandas AI](https://pandas-ai.com/)**: An extension of the Pandas library that integrates AI capabilities, enhancing data analysis workflows with intelligent data manipulation and insights.

- **[Lovable.dev | GPT Engineer](https://lovable.dev/)**: A platform offering tools and resources for developers working with GPT models, providing guidance and utilities to optimize AI application development.

- **[Flowise](https://flowiseai.com/)**: An open-source low-code tool for building customized LLM orchestration flows and AI agents, enabling quick iterations from testing to production. 

- **[Langflow](https://www.langflow.org/)**: A user-friendly platform designed to simplify the creation and sharing of applications built around foundation models, offering a modular and interactive design for rapid experimentation. 

- **[Llama Stack](https://github.com/meta-llama/llama-stack)**: Composable building blocks to build Llama Apps, defining and standardizing core components to simplify AI application development. 

- **[LLM Course](https://github.com/mlabonne/llm-course)**: A comprehensive course offering roadmaps and Colab notebooks to help learners delve into Large Language Models (LLMs), covering various aspects of LLM development and application. 

These resources provide a robust foundation for developers and researchers aiming to explore and implement advanced AI and machine learning applications. 


### Fine-tuning: Teach our AI a new Subject
These courses focus on fine-tuning large language models (LLMs) to specialize them for new subjects or tasks. Learners explore tools and techniques for customizing models, including embedding fine-tuning, and debugging generative AI systems. With hands-on resources from OpenAI, Activeloop, and DeepLearning.ai, these courses empower users to adapt LLMs to specific domains for improved accuracy and relevance.


- **[Fine-Tuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)**: A short course by DeepLearning.AI that provides practical guidance on fine-tuning large language models, covering techniques to adapt models for specific tasks and improve performance.

- **[Activeloop | Training & Fine-Tuning LLMs for Production](https://learn.activeloop.ai/courses/llms)**: A free course offering comprehensive insights into training and fine-tuning large language models for production environments, including practical projects and theoretical lessons. 

- **[OpenAI Fine-Tuning Guide](https://platform.openai.com/docs/guides/fine-tuning)**: Official documentation from OpenAI detailing the process of fine-tuning their models, providing step-by-step instructions and best practices for customizing models to specific applications. 

- **[Evaluating and Debugging Generative AI Models Using Weights and Biases](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai/)**: A course that teaches how to evaluate and debug generative AI models using the Weights & Biases platform, focusing on tracking experiments, managing data versions, and improving model performance. 

- **[Fine-Tuning Embeddings](https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html)**: A guide on fine-tuning embeddings to enhance the performance of language models in specific tasks, providing practical examples and methodologies.

- **[Unsloth: Efficient Fine-Tuning](https://github.com/unslothai/unsloth)**: A tool that enables efficient fine-tuning of models like Llama 3.3, Mistral, and others, achieving faster performance with reduced memory usage. 

- **[Hugging Face AutoTrain](https://huggingface.co/autotrain)**: A platform that allows users to automatically train, evaluate, and deploy state-of-the-art machine learning models without coding, supporting various tasks including LLM fine-tuning.
- **[Unsloth notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks)**: Collection of notebooks, fine tune, inference, RL algorithms.

These resources offer valuable guidance and tools for fine-tuning large language models and enhancing their performance across various applications. 


## Research:
These research-focused resources provide access to cutting-edge advancements in AI from leading organizations like OpenAI, DeepMind, and Google Research. Platforms like Arxiv and Hugging Face Papers offer a wealth of scholarly articles, enabling learners to explore the latest innovations in AI agents, generative models, and more. Staying updated with these resources is essential for those aiming to contribute to or stay ahead in the evolving AI landscape.


- **[ArXiv: AI Agent Research](https://arxiv.org/search/?query=AI+agent&searchtype=all&abstracts=show&order=-announced_date_first&size=50)**: A comprehensive repository of the latest research papers on AI agents, offering a wide range of studies and findings from the academic community.

- **[Hugging Face Papers](https://huggingface.co/papers)**: A curated collection of trending AI research papers, updated daily, providing insights into recent advancements and methodologies in the field.

- **[OpenAI Research](https://openai.com/news/research/)**: OpenAI's official research portal, featuring publications and updates on their latest AI models, safety protocols, and technological breakthroughs.

- **[Meta AI Research](https://research.facebook.com/)**: Meta's platform showcasing their AI research initiatives, including publications, projects, and collaborations aimed at advancing artificial intelligence.

- **[Google Research](https://research.google/)**: Google's research division presents a wide array of studies and developments in AI and other scientific domains, highlighting their contributions to technology and innovation.

- **[DeepMind Research](https://deepmind.google/research/)**: DeepMind's repository of research papers and articles, detailing their work on complex AI challenges and their applications across various fields.

- **[Anthropic Research](https://www.anthropic.com/research)**: Anthropic's research page focuses on developing large-scale AI systems with an emphasis on safety, reliability, and ethical considerations.

These resources provide valuable insights into current AI research and developments, supporting further exploration and understanding of the field. 

  
## Book And reading resources:

- **[Foundations of Large Language Models](https://arxiv.org/pdf/2501.09223)**: A comprehensive research paper that delves into the underlying principles and architectures of large language models, providing a solid theoretical foundation for understanding their development and applications.

- **[LLM Patterns](https://eugeneyan.com/writing/llm-patterns/)**: An insightful article by Eugene Yan that explores common design patterns in large language models, offering practical guidance on their implementation and optimization.

- **[Introduction to Large Language Models](https://docs.cohere.com/docs/introduction-to-large-language-models)**: A beginner-friendly guide by Cohere that introduces the basics of large language models, covering their architecture, training processes, and potential applications.

- **[KDnuggets](https://www.kdnuggets.com/)**: A leading platform offering a wealth of resources on data science, machine learning, and AI, including tutorials, articles, and industry news to keep practitioners informed and updated.

- **[MLOps](https://huyenchip.com/mlops/)**: A comprehensive resource by Chip Huyen that discusses the practices and tools for deploying and maintaining machine learning models in production, emphasizing scalability and reliability.

- **[Langchain Use Cases](https://python.langchain.com/docs/use_cases/)**: A collection of practical examples demonstrating how to implement various applications using Langchain, a framework for developing applications powered by language models.

- **[LLM Auto Eval Best Practices RAG](https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG)**: An article by Databricks discussing best practices for the automated evaluation of large language models, focusing on Retrieval-Augmented Generation (RAG) techniques.

- **[Hugging Face Cookbook](https://huggingface.co/learn/cookbook/en/index)**: A collection of practical recipes and tutorials by Hugging Face, guiding users through various tasks in natural language processing and machine learning using their libraries and tools.

- **[Evaluating with LLMs](https://mlflow.org/docs/latest/models.html#evaluating-with-llms)**: Documentation by MLflow on how to evaluate machine learning models using large language models, providing guidelines for assessment and validation.

- **[Unsloth: Efficient Fine-Tuning](https://github.com/unslothai/unsloth)**: A tool that enables efficient fine-tuning of models like Llama 3.3, Mistral, and others, achieving faster performance with reduced memory usage.

- **[Hugging Face AutoTrain](https://huggingface.co/autotrain)**: A platform that allows users to automatically train, evaluate, and deploy state-of-the-art machine learning models without coding, supporting various tasks including LLM fine-tuning.

- **[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)**: A framework for unified and efficient fine-tuning of over 100 large language and vision-language models, facilitating streamlined customization for diverse applications.

- **[AI Agent Whitepaper](https://www.kaggle.com/whitepaper-agents)**: A comprehensive whitepaper hosted on Kaggle that explores the development and deployment of AI agents, discussing methodologies, challenges, and case studies.

These resources offer valuable insights and tools for understanding, developing, and deploying large language models and AI agents across various applications. 

 
## UI and Local LLM  for POC
Build stunning AI applications effortlessly using simple UI libraries like Streamlit and Chainlit for your proof-of-concept projects. Harness powerful local LLMs such as Ollama, LMStudio, and VLLM for advanced text generation, while creating scalable backend services with FastAPI. Tap into the extensive collection of open-source models from Hugging Face to bring your Generative AI ideas to life.

- **[Hugging Face Models](https://huggingface.co/models)**: A comprehensive repository of pre-trained machine learning models across various modalities, including NLP, vision, and more, facilitating easy integration and fine-tuning for diverse applications.

- **[Langchain](https://python.langchain.com/docs/get_started/introduction)**: A framework designed to simplify the development of applications powered by large language models, offering tools for prompt management, LLM chaining, data augmentation, and more.

- **[LlamaIndex](https://www.llamaindex.ai/)**: An interface that connects large language models with external data sources, enabling efficient data retrieval and interaction for enhanced AI applications.

- **[Unstructured-IO](https://github.com/Unstructured-IO/unstructured)**: A Python library that provides pre-processing tools for unstructured data, converting it into structured formats suitable for analysis and machine learning tasks.

- **[Chainlit](https://docs.chainlit.io/get-started/overview)**: A framework for creating conversational AI applications, allowing developers to build, test, and deploy chatbots with ease.

- **[Streamlit](https://docs.streamlit.io/)**: An open-source app framework in Python that enables the creation of interactive web applications for data science and machine learning projects with minimal effort.

- **[Text-Generation-WebUI](https://github.com/oobabooga/text-generation-webui)**: A Gradio-based web interface for running large language models, supporting multiple inference backends for text generation tasks. 

- **[LM Studio](https://lmstudio.ai/)**: A platform that allows users to discover, download, and run local large language models on their computers, supporting architectures like Llama 3.2, Mistral, and more. 

- **[Anything LLM](https://anythingllm.com/)**: An all-in-one AI application that enables users to chat with documents, utilize AI agents, and run models locally and offline, ensuring full privacy. 

- **[Ollama](https://ollama.com/)**: A tool that facilitates running large language models like Llama 3.3, DeepSeek-R1, and others locally on macOS, Linux, and Windows platforms. 

- **[vLLM](https://github.com/vllm-project/vllm)**: A high-throughput and memory-efficient inference and serving engine for large language models, designed to optimize performance and resource utilization. 

- **[FastAPI](https://fastapi.tiangolo.com/)**: A modern, fast (high-performance) web framework for building APIs with Python 3.7+ based on standard Python type hints, ensuring quick development and robust code. 

These resources offer a range of tools and frameworks to support the development and deployment of AI and machine learning applications across various domains. 

## Readymade API-based/self-hosted LLM platform

- **[Gemini API](https://ai.google.dev/gemini-api/docs/api-key)**: Provides access to Google's Gemini models, enabling developers to integrate advanced AI capabilities into their applications.

- **[Together AI](https://www.together.ai/)**: An AI acceleration platform offering fast inference, fine-tuning, and training services for over 200 generative AI models, including chat, image, code, and more. 

- **[Anyscale](https://www.anyscale.com/)**: Empowers developers to build, deploy, and manage scalable AI and machine learning applications with ease, leveraging the Ray framework for distributed computing. 

- **[Replicate](https://replicate.com/)**: Enables running and fine-tuning open-source models, as well as deploying custom models at scale, all accessible via a simple API. 

- **[DeepInfra](https://deepinfra.com/)**: Offers fast machine learning inference through a simple API, providing access to top AI models with scalable and production-ready infrastructure. 

- **[Hugging Face Models](https://huggingface.co/models)**: A comprehensive repository of pre-trained machine learning models across various modalities, including NLP, vision, and more, facilitating easy integration and fine-tuning for diverse applications. 

These resources offer a range of tools and platforms to support the development and deployment of AI and machine learning applications across various domains. 

 
## Cloud Services:
These cloud services courses leverage platforms like AWS Bedrock, Azure AI, and GCP Vertex AI to deploy and manage AI solutions at scale. Learners gain practical knowledge in using cloud-based tools for building, fine-tuning, and operationalizing large language models (LLMs). With a strong emphasis on hands-on implementation, these resources prepare participants to harness the power of AI in enterprise-grade cloud environments.


- **[Amazon Bedrock](https://aws.amazon.com/bedrock/)**: A fully managed service by AWS that provides access to foundation models from leading AI companies via a single API, enabling the development of generative AI applications with security and scalability. ([aws.amazon.com](https://aws.amazon.com/bedrock/?utm_source=chatgpt.com))

- **[Azure AI Services](https://azure.microsoft.com/en-us/products/ai-services)**: A suite of AI services by Microsoft Azure offering capabilities such as language understanding, computer vision, and document processing to build intelligent applications. ([azure.microsoft.com](https://azure.microsoft.com/en-us/products/ai-services?utm_source=chatgpt.com))

- **[Azure AI Studio](https://learn.microsoft.com/en-us/training/modules/introduction-to-azure-ai-studio/)**: A platform within Azure that provides tools and resources for building, training, and deploying AI models, facilitating the development of intelligent applications.

- **[Google Cloud Vertex AI](https://cloud.google.com/vertex-ai)**: Google Cloud's unified AI platform that offers access to the latest Gemini models, enabling the development and deployment of machine learning models at scale. ([cloud.google.com](https://cloud.google.com/vertex-ai?utm_source=chatgpt.com))

- **[Large Language Model Operations (LLMOps) Specialization](https://www.coursera.org/specializations/large-language-model-operations)**: A Coursera specialization that provides expertise in deploying, managing, and optimizing large language models across various platforms, including Azure, AWS, and local infrastructure. 

These resources offer comprehensive tools and knowledge for developing, deploying, and managing AI and machine learning applications across various cloud platforms. 

# GenAI Apps and Projects
## Chunking Strategy

- **[Chonkie](https://github.com/chonkie-ai/chonkie/tree/main)**: An open-source tool designed to enhance text processing by implementing efficient chunking strategies, facilitating better handling of large documents in AI applications.

- **[Semchunk](https://github.com/umarbutler/semchunk)**: A semantic chunking tool that segments text into meaningful units, improving the performance of language models by providing contextually relevant chunks.

- **[LlamaIndex: Chunking](https://docs.llamaindex.ai/en/stable/examples/node_parsers/semantic_chunking/)**: Documentation on semantic chunking within LlamaIndex, offering examples and guidance on parsing nodes for optimized data processing.

- **[Langchain Chunking](https://js.langchain.com/v0.1/docs/modules/data_connection/document_transformers/)**: Provides methods for transforming documents through chunking, enabling more efficient data handling in language model pipelines.

- **[Unstructured.io: Chunking](https://docs.unstructured.io/open-source/core-functionality/chunking)**: Offers core functionalities for chunking unstructured data, aiding in converting complex documents into manageable pieces for analysis.

- **[Microsoft: Markitdown](https://github.com/microsoft/markitdown)**: A tool by Microsoft that assists in converting markdown content into structured formats, facilitating better data organization and accessibility.

## Vector Databases

- **[OpenAI Vector Database Implementation](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases)**: Examples from OpenAI's cookbook demonstrating how to implement vector databases for efficient similarity search and retrieval in AI applications.

- **[Vector Database Overview](https://thedataquarry.com/posts/vector-db-1/)**: An informative post providing an overview of vector databases, discussing their importance and applications in managing high-dimensional data.

- **[Chroma DB](https://www.trychroma.com/)**: An open-source, local-first vector database focusing on simplicity and performance, suitable for embedding and retrieval tasks in machine learning projects.

- **[Pinecone Examples](https://docs.pinecone.io/page/examples)**: A collection of examples demonstrating how to use Pinecone's vector database for building scalable and efficient similarity search solutions.

- **[Weaviate DB](https://weaviate.io/)**: An open-source vector database that allows for seamless integration of various data types, offering powerful search and retrieval capabilities.

- **[Milvus](https://milvus.io/)**: A high-performance, open-source vector database designed for scalable similarity search, widely used in AI and machine learning applications.

- **[Qdrant](https://qdrant.tech/)**: An open-source vector similarity search engine and database, optimized for performance and scalability in handling large-scale AI workloads.

- **[Vector Database Comparison](https://superlinked.com/vector-db-comparison)**: A comparative analysis of various vector databases, highlighting their features, performance benchmarks, and suitability for different use cases.

These resources provide valuable tools and insights for implementing chunking strategies and utilizing vector databases in AI and machine learning projects. 

## RAG and Evaluation:

- **[Azure Cognitive Search and Langchain Integration](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/azure-cognitive-search-and-langchain-a-seamless-integration-for-enhanced-vector-/3901448)**: This blog post discusses the seamless integration between Azure Cognitive Search and Langchain, highlighting how this combination enhances vector search capabilities in AI applications.

- **[NVIDIA's Course on Building RAG Applications](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-15+V1)**: An NVIDIA Deep Learning Institute course that provides insights into building Retrieval-Augmented Generation (RAG) applications, focusing on leveraging large language models for improved information retrieval.

- **[Crawl4AI](https://github.com/unclecode/crawl4ai)**: An open-source project designed to crawl and scrape data from websites, facilitating the collection of datasets for AI training and analysis.

- **[RAGFlow](https://github.com/infiniflow/ragflow)**: An open-source Retrieval-Augmented Generation (RAG) engine based on deep document understanding, aiming to enhance the generation of contextually relevant responses. 

- **[Verba](https://github.com/weaviate/Verba)**: A Retrieval-Augmented Generation (RAG) chatbot powered by Weaviate, designed to provide contextually enriched responses by integrating retrieval mechanisms with generative models. 

- **[GraphRAG](https://microsoft.github.io/graphrag/)**: A structured, hierarchical approach to Retrieval-Augmented Generation (RAG) that involves extracting a knowledge graph from raw text and leveraging this structure to enhance LLM reasoning about private data. 

- **[Building and Evaluating Advanced RAG Applications](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/)**: A short course by DeepLearning.AI that explores advanced retrieval methods and evaluation metrics to improve the performance of RAG pipelines. 

- **[Arize's RAG Evaluation Metrics Starter Kit](https://arize.com/blog-course/rag-evaluation/)**: A resource that provides workflows and metrics for troubleshooting and evaluating Retrieval-Augmented Generation systems, focusing on retrieval and response evaluation. 

These resources offer valuable insights and tools for developing, integrating, and evaluating Retrieval-Augmented Generation (RAG) systems in AI applications. 

## Router Models

- **[RouteLLM](https://github.com/lm-sys/RouteLLM)**: An open-source project that focuses on routing strategies for large language models, aiming to optimize performance and efficiency in various AI applications.

- **[ModernBERT](https://github.com/AnswerDotAI/ModernBERT)**: A modern implementation of the BERT model, designed to enhance natural language understanding tasks with improved architecture and training techniques.

## AI Safety

- **[Responsible AI Engineering](https://research.csiro.au/ss/team/se4ai/responsible-ai-engineering/)**: A resource by CSIRO discussing methodologies and best practices for responsible AI engineering, emphasizing ethical considerations and safety in AI system development.

- **[International AI Safety Report 2025](https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf)**: A comprehensive report outlining the global state of AI safety as of 2025, providing insights into regulatory frameworks, risk assessments, and recommendations for future AI governance.

## Notable Notebooks

- **[OpenAI Cookbook](https://github.com/openai/openai-cookbook)**: A collection of examples and guides demonstrating how to use OpenAI's API for various applications, including code snippets and best practices.

- **[Autogen Examples](https://microsoft.github.io/autogen/0.2/docs/Examples)**: A set of examples showcasing the use of Microsoft's Autogen framework for automated code generation and other AI-driven development tasks.

- **[Anthropic Cookbook](https://github.com/anthropics/anthropic-cookbook)**: A repository of resources and examples from Anthropic, focusing on building and understanding large-scale AI models with an emphasis on safety and interpretability.

- **[Build Hours](https://github.com/openai/build-hours)**: Code and resources shared during OpenAI's Build Hours events, aimed at helping developers explore and implement OpenAI's models in various projects.

- **[Awesome LLM Apps](https://github.com/Shubhamsaboo/awesome-llm-apps)**: A curated collection of applications and projects utilizing large language models, highlighting innovative uses across different domains.

- **[LLM Course](https://github.com/mlabonne/llm-course)**: A comprehensive course designed to introduce learners to large language models, complete with roadmaps and Colab notebooks for hands-on experience.

These resources offer valuable insights and tools for exploring router models, ensuring AI safety, and engaging with practical applications and educational materials related to large language models. 


## Other projects:

## AI Projects and Tools

- **[OpenHands](https://github.com/All-Hands-AI/OpenHands)**: An open-source platform designed to facilitate collaborative AI research and development, providing tools and resources for the AI community.

- **[CopilotKit](https://github.com/CopilotKit/CopilotKit)**: A toolkit that enhances the capabilities of AI copilots, offering customizable features to improve user interaction and productivity.

- **[Eliza](https://github.com/elizaOS/eliza)**: An AI-driven operating system that integrates advanced language models to provide intuitive user experiences and automate tasks.

- **[Fish Speech](https://github.com/fishaudio/fish-speech)**: A speech recognition project focused on developing efficient and accurate models for transcribing audio inputs.

- **[AnythingLLM](https://anythingllm.com/)**: A platform that offers tools and resources for working with large language models, including fine-tuning and deployment solutions.

- **[Open Canvas](https://github.com/langchain-ai/open-canvas)**: An open-source project that provides a visual interface for designing and managing complex language model workflows.

- **[Awesome LLM Apps](https://github.com/Shubhamsaboo/awesome-llm-apps)**: A curated list of applications and projects utilizing large language models, showcasing innovative uses across various domains.

- **[Khoj](https://github.com/khoj-ai/khoj)**: An AI-powered search assistant that helps users find information quickly by understanding natural language queries.

- **[Awesome Generative AI](https://github.com/steven2358/awesome-generative-ai)**: A comprehensive collection of resources, tools, and research papers related to generative AI.

- **[OpenAI Realtime Agents](https://github.com/openai/openai-realtime-agents)**: A demonstration of advanced agent patterns built on top of OpenAI's Realtime API, showcasing sequential agent handoffs and background escalations. 

- **[LLMOps Database](https://www.zenml.io/llmops-database)**: A curated knowledge base of real-world implementations of Large Language Model Operations (LLMOps), providing detailed summaries and technical notes.

## Build from Scratch
-**[Let's build GPT: from scratch](https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathy)**: GPT implementation from scratch hands on.

## Leaderboards

- **[MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)**: A leaderboard showcasing the performance of models on the Massive Text Embedding Benchmark (MTEB), highlighting top-performing models in text embedding tasks. 

- **[Open LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/?params=0%2C9)**: A platform that ranks open-source large language models based on various benchmarks, providing insights into their performance and capabilities. 

- **[LMArena](https://lmarena.ai/)**: A platform that evaluates and compares large language models across different tasks, providing a comprehensive performance analysis. 

- **[LLM Compare](https://yourgpt.ai/tools/llm-comparison-and-leaderboard)**: A tool that allows users to compare large language models based on key metrics such as performance, cost, and speed. 

- **[Vellum LLM Leaderboard](https://www.vellum.ai/llm-leaderboard)**: A leaderboard that ranks large language models based on various benchmarks, providing insights into their strengths and weaknesses across different tasks. 

These resources offer a range of tools, projects, and comparative analyses to support the development and evaluation of large language models and AI applications. 
